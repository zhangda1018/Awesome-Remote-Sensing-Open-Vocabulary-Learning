
# Awesome-Remote-Sensing-Open-Vocabulary-Learning



üî•üî•üî• **Towards Open-Vocabulary Learning in Remote Sensing: A Survey**  
<!-- **[Project Page][This Page](https://github.com/ZhanYang-nwpu/RS-MLLMs)** |  -->


<div align='center'> ‚ú® The <b>first survey</b> for Open-Vocabulary Learning for Remote Sensing (RS-OV). </div>  



‚ú®‚ú®‚ú® Behold our meticulously curated trove of RS-OV resources!!!

üéâüöÄüí° The website will be updated in real-time to track the latest state of RS-OV!!!



## Please share a <font color='orange'>STAR ‚≠ê</font> if this project does help




## üì¢ Latest Updates
- **The list will be continuously updated** üî•üî•


---
<font size=5><center><b> Table of Contents </b> </center></font>
- [Open Vocabulary Object Detection for Remote Sensing](#open-vocabulary-object-detection-for-remote-sensing)
- [Open Vocabulary Semantic Segmentation for Remote Sensing](#open-vocabulary-semantic-segmentation-for-remote-sensing)
- [Open Vocabulary Instance Segmentation for Remote Sensing](#open-vocabulary-instance-segmentation-for-remote-sensing)
- [Open Vocabulary Change Detection for Remote Sensing](#open-vocabulary-change-detection-for-remote-sensing)
- [Open Vocabulary Visual Grounding for Remote Sensing](#open-vocabulary-visual-grounding-for-remote-sensing)
- [Other](#other)
- [Foundation Model & Datasets](#foundation-model--datasets)
---




## Open Vocabulary Object Detection for Remote Sensing
|  Title  |   Venue  |   Date   |   Code   |   Note   |
|:--------|:--------:|:--------:|:--------:|:--------:|
|  [LLaMA-Unidetector: An LLaMA-Based Universal Framework for Open-Vocabulary Object Detection in Remote Sensing Imagery](https://ieeexplore.ieee.org/abstract/document/10976651) <br>J Xie, G Wang, T Zhang, Y Sun, H Chen, Y. Zhang. <br>| TGRS | 2025 | [Github](https://github.com/ChloeeGrace/LLaMA-Unidetector) | - |
|  [RT-OVAD: Real-Time Open-Vocabulary Aerial Object Detection via Image-Text Collaboration](https://arxiv.org/abs/2408.12246v3) <br>G Wei, X Yuan, Y Liu, Z Shang, X Xue, P Wang, K Yao, C Zhao, H Zhang, R Xiao. <br>| Arxiv | 2025 | [Github](https://github.com/GT-Wei/RT-OVAD) | - |
|  [OpenRSD: Towards Open-prompts for Object Detection in Remote Sensing Images](https://openaccess.thecvf.com/content/ICCV2025/html/Huang_OpenRSD_Towards_Open-prompts_for_Object_Detection_in_Remote_Sensing_Images_ICCV_2025_paper.html) <br>Z Huang, Y Feng, S Yang, Z Liu, Q Liu, Y Wang. <br>| ICCV | 2025 | [Github](https://github.com/floatingstarZ/OpenRSD) | - |
|  [Cross-View Open-Vocabulary Object Detection in Aerial Imagery](https://arxiv.org/abs/2510.03858) <br>J Kini, R Gupta, M Shah. <br>| Arxiv | 2025 | - | - |
|  [FASE: Feature-Aligned Scene Encoding for Open-Vocabulary Object Detection in Remote Sensing](https://dl.acm.org/doi/abs/10.1145/3746252.3760838) <br>H Hwang, SS Woo. <br>| CIKM | 2025 | - | - |
|  [Cross-View Open-Vocabulary Object Detection in Aerial Imagery](https://arxiv.org/abs/2510.03858) <br>J Kini, R Gupta, M Shah. <br>| Arxiv | 2025 | - | - |
|  [Mask-Guided Teacher‚ÄìStudent Learning for Open-Vocabulary Object Detection in Remote Sensing Images](https://www.mdpi.com/2072-4292/17/19/3385) <br>J S Wang, Y Song, J Xiang, Y Chen, P Zhong, R Fu. <br>| Remote Sensing | 2025 | - | - |
|  [Locate anything on earth: Advancing open-vocabulary object detection for remote sensing community](https://ojs.aaai.org/index.php/AAAI/article/view/32672) <br>J Pan, Y Liu, Y Fu, M Ma, J Li, DP Paudel, L Van Gool, X Huang. <br>| AAAI | 2025 | [Github](https://github.com/jaychempan/LAE-DINO) | - |
|  [Toward open vocabulary aerial object detection with clip-activated student-teacher learning ](https://link.springer.com/chapter/10.1007/978-3-031-73016-0_25) <br>Y Li, W Guo, X Yang, N Liao, D He, J Zhou, W Yu. <br>| ECCV | 2024 | [Github](https://github.com/VisionXLab/CastDethttps://github.com/VisionXLab/CastDet) | - |
|  [CLIP-guided source-free object detection in aerial images ](https://www.arxiv.org/abs/2401.05168) <br>N Liu, X Xu, Y Su, C Liu, P Gong, HC Li. <br>| IGARSS | 2024 | [Github](https://github.com/Lans1ng/SFOD-RS) | - |



## Open Vocabulary Semantic Segmentation for Remote Sensing
|  Title  |   Venue  |   Date   |   Code   |   Note   |
|:--------|:--------:|:--------:|:--------:|:--------:|
|  [Learning transferable land cover semantics for open vocabulary interactions with remote sensing images](https://www.sciencedirect.com/science/article/pii/S0924271625000061) <br>Val√©rie Zermatten, Javiera Castillo-Navarro, Diego Marcos, Devis Tuia.<br>| ISPRS | 2025 | [Github](https://github.com/eceo-epfl/RS-OVSS)  | - |
|  [CitySeg: A 3D Open Vocabulary Semantic Segmentation Foundation Model in City-scale Scenarios](https://arxiv.org/abs/2508.09470) <br>Jialei Xu, Zizhuang Wei, Weikang You, Linyun Li, Weijian Sun. <br>| Arxiv | 2025 | - | - |
|  [Soft-Guided Open-Vocabulary Semantic Segmentation of Remote Sensing Images](https://ieeexplore.ieee.org/document/11224558) <br>K An, Y Wang, L Chen. <br>| TGRS | 2025 | - | - |
|  [Exploring Efficient Open-Vocabulary Segmentation in the Remote Sensing](https://arxiv.org/pdf/2509.12040) <br>B Li, H Dong, D Zhang, Z Zhao, J Gao, X Li. <br>| AAAI | 2026 | [Github](https://github.com/LiBingyu01/RSKT-Seg) | - |
|  [Open-Vocabulary Semantic Segmentation for Remote Sensing Imagery via Dual-Stream Feature Extraction and Category-Adaptive Refinement](https://www.preprints.org/manuscript/202511.0513) <br>S Yuan, B He. <br>| Arxiv | 2025 | - | - |
|  [AerOSeg: Harnessing SAM for Open-Vocabulary Segmentation in Remote Sensing Images](https://openaccess.thecvf.com/content/CVPR2025W/EarthVision/html/Dutta_AerOSeg_Harnessing_SAM_for_Open-Vocabulary_Segmentation_in_Remote_Sensing_Images_CVPRW_2025_paper.html) <br>Saikat Dutta, Akhil Vasim, Siddhant Gole, Hamid Rezatofighi, Biplab Banerjee. <br>| CVPR workshop | 2025 | - | - |
|  [Towards Open-Vocabulary Remote Sensing Image Semantic Segmentation](https://www.preprints.org/manuscript/202511.0513) <br>C Ye, Y Zhuge, P Zhang. <br>| AAAI | 2025 | [Github](https://github.com/yecy749/GSNet) | - |
|  [Annotation-Free Open-Vocabulary Segmentation for Remote-Sensing Images](https://arxiv.org/abs/2508.18067) <br>K Li, X Cao, R Liu, S Wang, Z Jiang, Z Wang, D Meng. <br>| Arxiv | 2025 | [Github](https://github.com/earth-insights/SegEarth-OV-2) | - |
|  [SegEarth-OV: Towards Training-Free Open-Vocabulary Segmentation for Remote Sensing Images](https://www.arxiv.org/abs/2410.01768) <br>K Li, R Liu, X Cao, X Bai, F Zhou, D Meng, Z Wang. <br>| CVPR | 2025 | [Github](https://github.com/likyoo/SegEarth-OV) | - |
|  [Open-Vocabulary High-Resolution Remote Sensing Image Semantic Segmentation](https://ieeexplore.ieee.org/abstract/document/10962188) <br>Q Cao, Y Chen, C Ma, X Yang. <br>| TGRS | 2025 | [Github](https://github.com/caoql98/OVRS) | - |
|  [FreeMix: Open-Vocabulary Domain Generalization of Remote-Sensing Images for Semantic Segmentation](https://www.mdpi.com/2072-4292/17/8/1357) <br>J Wu, J Shi, Z Zhao, Z Liu, R Zhi. <br>| TGRS | 2025 | [Github](https://github.com/GoldfishFive/FreeMix) | - |
|  [Large multimodal model for open vocabulary semantic segmentation of remote sensing images](https://www.tandfonline.com/doi/full/10.1080/22797254.2024.2447344#abstract) <br>B Liu, X Chen, A Yu, F Feng, J Yue, X Yu. <br>| EJRS | 2025 | - | - |
|  [Expanding Open-Vocabulary Understanding for UAV Aerial Imagery: A Vision‚ÄìLanguage Framework to Semantic Segmentation](https://www.mdpi.com/2504-446X/9/2/155) <br>B Huang, J Li, W Luan, J Tan, C Li, L Huang. <br>| Drones | 2025 | - | - |
|  [RSCLIP for Training-Free Open-Vocabulary Remote Sensing Image Semantic Segmentation](https://www.techrxiv.org/doi/full/10.36227/techrxiv.175790902.28615776) <br>S Wang, X Sun, J Han, XX Zhu. <br>| Techrxiv | 2025 | - | - |
|  [AeriaICLIP: Lightweight Open-Vocabulary Segmentation for UAV-Based Aerial Images](https://ieeexplore.ieee.org/abstract/document/11179646) <br>P Jia, Y Gao, W Li, Q Gao, F Pan. <br>| CCC | 2025 | - | - |
|  [Toward High-Resolution UAV Imagery Open-Vocabulary Semantic Segmentation](https://www.mdpi.com/2504-446X/9/7/470) <br>Z Chen, Y Xie, Y Wei . <br>| Drones | 2025 | - | - |





## Open Vocabulary Instance Segmentation for Remote Sensing
|  Title  |   Venue  |   Date   |   Code   |   Note   |
|:--------|:--------:|:--------:|:--------:|:--------:|
|  [SCORE: Scene Context Matters in Open-Vocabulary Remote Sensing Instance Segmentation](https://arxiv.org/abs/2507.12857) <br>S Huang, S He, H Qin, B Wen. <br>| ICCV | 2025 | [Github](https://github.com/HuangShiqi128/SCORE) | - |
|  [ZoRI: Towards Discriminative Zero-Shot Remote Sensing Instance Segmentation](https://ojs.aaai.org/index.php/AAAI/article/view/32388) <br>Shiqi Huang, Shuting He, Bihan Wen. <br>| AAAI | 2025 | [Github](https://github.com/HuangShiqi128/ZoRI) | - |





## Open Vocabulary Change Detection for Remote Sensing
|  Title  |   Venue  |   Date   |   Code   |   Note   |
|:--------|:--------:|:--------:|:--------:|:--------:|
|  [DynamicEarth: How Far are We from Open-Vocabulary Change Detection?](https://arxiv.org/abs/2501.12931) <br>K Li, X Cao, Y Deng, C Pang, Z Xin, D Meng, Z Wang. <br>| Arxiv | 2025 | [Github](https://github.com/likyoo/DynamicEarth) | Accepted by AAAI 2026 |
|  [Semantic-cd: Remote sensing image semantic change detection towards open-vocabulary setting](https://arxiv.org/abs/2501.06808) <br>Y Zhu, L Li, K Chen, C Liu, F Zhou, Z Shi. <br>| Arxiv | 2025 | - | - |
|  [Open-vocabulary generative vision-language models for creating a large-scale remote sensing change detection dataset](https://www.sciencedirect.com/science/article/abs/pii/S0924271625001595) <br>Y Zan, S Ji, S Chao, M Luo. <br>| ISPRS | 2025 | [Github](https://gpcv.whu.edu.cn/data/) | - |


## Open Vocabulary Visual Grounding for Remote Sensing
|  Title  |   Venue  |   Date   |   Code   |   Note   |
|:--------|:--------:|:--------:|:--------:|:--------:|
|  [RSVG-ZeroOV: Exploring a Training-Free Framework for Zero-Shot Open-Vocabulary Visual Grounding in Remote Sensing Images](https://www.arxiv.org/abs/2509.18711v2) <br>K Li, D Wang, T Wang, F Dong, Y Zhang, L Zhang, X Wang, S Li, Q Wang. <br>| AAAI | 2026 | - | - |




## Other
|  Title  |   Venue  |   Date   |   Code   |   Note   |
|:--------|:--------:|:--------:|:--------:|:--------:|
|  [FarSLIP: Discovering Effective CLIP Adaptation for Fine-Grained Remote Sensing Understanding](https://arxiv.org/pdf/2511.14901) <br>Zhenshi Li, Weikang Yu, Dilxat Muhtar, Xueliang Zhang, Pengfeng Xiao, Pedram Ghamisi, Xiaoxiang Zhu. <br>| Arxiv | 2025 | [Github](https://github.com/NJU-LHRS/FarSLIP) | - |
|  [Grounded Vision-Language Navigation for UAVs with Open-Vocabulary Goal Understanding](https://arxiv.org/abs/2506.10756) <br>Yuhang Zhang, Haosheng Yu, Jiaping Xiao, Mir Feroskhan. <br>| Arxiv | 2025 | [Github](https://zzzzzyh111.github.io/VLFly/) | - |
|  [Enhanced Grounding DINO: Efficient Cross-Modality Block for Open-Set Object Detection in Remote Sensing](https://ieeexplore.ieee.org/abstract/document/11021309) <br>Z Hu, K Gao, J Wang, Z Yang, Z Zhang, H Chen. <br>| JSTAR | 2025 | - | - |
|  [Advancing Open-Set Object Detection in Remote Sensing Using Multimodal Large Language Model](https://openaccess.thecvf.com/content/WACV2025W/GeoCV/html/Saini_Advancing_Open-Set_Object_Detection_in_Remote_Sensing_Using_Multimodal_Large_WACVW_2025_paper.html) <br>Nandini Saini, Ashudeep Dubey, Debasis Das, Chiranjoy Chattopadhyay. <br>| WACV Workshop | 2025 | - | - |
|  [GeoRSMLLM: A Multimodal Large Language Model for Vision-Language Tasks in Geoscience and Remote Sensing](https://arxiv.org/abs/2503.12490) <br>Zilun Zhang, Haozhan Shen, Tiancheng Zhao, Bin Chen, Zian Guan, Yuhao Wang, Xu Jia, Yuxiang Cai, Yongheng Shang, Jianwei Yin. <br>| Arxiv | 2025 | - | - |
|  [InstructSAM: A Training-Free Framework for Instruction-Oriented Remote Sensing Object Recognition](https://www.arxiv.org/abs/2505.15818) <br>Y Zheng, W Wu, Q Li, X Wang, X Zhou, A Ren, J Shen, L Zhao, G Li, X Yang. <br>| Neurips | 2025 | [Github](https://voyagerxvoyagerx.github.io/InstructSAM/) | - |
|  [SkySense-O: Towards Open-World Remote Sensing Interpretation with Vision-Centric Visual-Language Modeling](https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_SkySense-O_Towards_Open-World_Remote_Sensing_Interpretation_with_Vision-Centric_Visual-Language_Modeling_CVPR_2025_paper.html) <br>Q Zhu, J Lao, D Ji, J Luo, K Wu, Y Zhang, L Ru, J Wang, J Chen, M Yang, D Liu, F Zhao. <br>| CVPR | 2025 | [Github](https://github.com/zqcrafts/SkySense-O) | - |
|  [DDFAV: Remote Sensing Large Vision Language Models Dataset and Evaluation Benchmark](https://arxiv.org/abs/2501.16222) <br>H Li, X Zhang, H Qu. <br>| Remote Sensing | 2025 | [Github](https://github.com/HaodongLi2024/rspope) | - |
|  [SPECIAL: zero-shot hyperspectral image classification with CLIP](https://arxiv.org/abs/2501.16222) <br>L Pang, J Yao, K Li, X Cao. <br>| Arxiv | 2025 | [Github](https://github.com/LiPang/SPECIAL) | - |
|  [RS-CLIP: Zero shot remote sensing scene classification via contrastive vision-language supervision](https://www.sciencedirect.com/science/article/pii/S1569843223003217) <br>X Li, C Wen, Y Hu, N Zhou. <br>| Arxiv | 2024 | [Github](https://github.com/lx709/RS-CLIP) | - |
|  [Remote Sensing Vision-Language Foundation Models without Annotations via Ground Remote Alignment](https://openreview.net/forum?id=w9tc699w3Z) <br>Utkarsh Mall, Cheng Perng Phoo, Meilin Kelsey Liu, Carl Vondrick, Bharath Hariharan, Kavita Bala. <br>| ICLR | 2024 | [Github](https://graft.cs.cornell.edu/) | - |




## Foundation Model & Datasets
| Name | Paper | Github | Year |
|:-----|:-----:|:----:|:-----:|
| **AetherVision-Bench** | [AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives](https://arxiv.org/abs/2506.03709) | - | 2025|
| **Falcon** | [Falcon: A Remote Sensing Vision-Language Foundation Model](https://arxiv.org/abs/2503.11070) | [Link](https://github.com/TianHuiLab/Falcon) | 2025|
| **RemoteSAM** | [Remotesam: Towards segment anything for earth observation](https://www.arxiv.org/abs/2505.18022) | [Link](https://github.com/1e12Leon/RemoteSAM) | 2025|
| **SkyEyeGPT** | [SkyEyeGPT: Unifying Remote Sensing Vision-Language Tasks via Instruction Tuning with Large Language Model](https://www.arxiv.org/abs/2401.09712) | [Link](https://github.com/ZhanYang-nwpu/SkyEyeGPT) | 2025|
| **OS-W2S** | [OS-W2S: An Automatic Labeling Engine for Language-Guided Open-Set Aerial Object Detection](https://arxiv.org/abs/2505.03334) | [Link](https://github.com/GT-Wei/MI-OAD) | 2025|
| **OVRSISBench** | [Exploring Efficient Open-Vocabulary Segmentation in the Remote Sensing](https://arxiv.org/abs/2509.12040) | [Link](https://github.com/LiBingyu01/RSKT-Seg) | 2025|
| **Git-10M** | [Text2Earth: Unlocking Text-driven Remote Sensing Image Generation with a Global-Scale Dataset and a Foundation Model](https://ieeexplore.ieee.org/document/10988859) | [Link](https://github.com/chen-yang-liu/Text2Earth) | 2025 | 
| **LAE-1M** | [Locate Anything on Earth: Advancing Open-Vocabulary Object Detection for Remote Sensing Community](https://arxiv.org/abs/2408.09110) | [Link](https://github.com/jaychempan/LAE-DINO) | 2024
| **RemoteCLIP** | [ RemoteCLIP: A Vision Language Foundation Model for Remote Sensing](https://ieeexplore.ieee.org/abstract/document/10504785) | [Link](https://github.com/ChenDelong1999/RemoteCLIP) | 2024
| **DDFAV** | [DDFAV: Remote Sensing Large Vision Language Models Dataset and Evaluation Benchmark](https://www.mdpi.com/2072-4292/17/4/719) | [Link](https://github.com/HaodongLi2024/rspope) | 2024
| **LandDiscover50K** | [Towards Open-Vocabulary Remote Sensing Image Semantic Segmentation](https://arxiv.org/abs/2412.19492) | [Link](https://github.com/yecy749/GSNet) | 2024 | 
| **SkyScript** | [SkyScript: A Large and Semantically Diverse Vision-Language Dataset for Remote Sensing](https://arxiv.org/abs/2312.12856) | [Link](https://github.com/wangzhecheng/SkyScript) | 2023 | 
| **RS5M** | [RS5M and GeoRSCLIP: A Large Scale Vision-Language Dataset and A Large Vision-Language Model for Remote Sensing](https://arxiv.org/abs/2306.11300) | [Link](https://github.com/om-ai-lab/RS5M) | 2023 | 






## ü§ñ Contact
If you have any questions about this project, please feel free to contact us.




